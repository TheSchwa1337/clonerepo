from utils.safe_print import safe_print, info, warn, error, success, debug
from core.unified_math_system import unified_math
#!/usr/bin/env python3
"""
Persistent Homology - Schwabot UROS v1.0
========================================

Implements persistent homology for topological data analysis in trading patterns.
Critical for detecting persistent features in market data and price movements.
"""

from typing import List, Tuple, Dict, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


@dataclass
class Simplex:
    """Represents a simplex in the simplicial complex."""
    vertices: List[int]
    dimension: int
    birth_time: float
    death_time: Optional[float] = None
    persistence: Optional[float] = None
    
    def __post_init__(self):
        """Compute dimension and persistence after initialization."""
        self.dimension = len(self.vertices) - 1
        if self.death_time is not None:
            self.persistence = self.death_time - self.birth_time


@dataclass
class PersistentFeature:
    """Represents a persistent feature in the data."""
    feature_id: str
    dimension: int
    birth_time: float
    death_time: float
    persistence: float
    vertices: List[int]
    confidence: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)


class PersistentHomology:
    """
    Implements persistent homology for topological data analysis.
    Analyzes persistent features in market data and trading patterns.
    """
    
    def __init__(self):
        """Initialize the persistent homology analyzer."""
        self.simplices: List[Simplex] = []
        self.persistent_features: List[PersistentFeature] = []
        self.filtration: List[float] = []
        self.complex_history: List[List[Simplex]] = []
        
        # Analysis parameters
        self.max_dimension = 3
        self.persistence_threshold = 0.1
        self.confidence_threshold = 0.7
        
        logger.info("Persistent Homology analyzer initialized")
    
    def build_simplicial_complex(self, points: np.ndarray, max_distance: float) -> List[Simplex]:
        """Build simplicial complex from point cloud data."""
        n_points = len(points)
        simplices = []
        
        # Add 0-simplices (vertices)
        for i in range(n_points):
            simplices.append(Simplex(vertices=[i], dimension=0, birth_time=0.0))
        
        # Add 1-simplices (edges)
        for i in range(n_points):
            for j in range(i + 1, n_points):
                distance = np.linalg.norm(points[i] - points[j])
                if distance <= max_distance:
                    birth_time = distance
                    simplices.append(Simplex(vertices=[i, j], dimension=1, birth_time=birth_time))
        
        # Add higher-dimensional simplices (triangles, tetrahedra)
        if self.max_dimension >= 2:
            simplices.extend(self._build_triangles(points, max_distance))
        
        if self.max_dimension >= 3:
            simplices.extend(self._build_tetrahedra(points, max_distance))
        
        # Sort by birth time
        simplices.sort(key=lambda s: s.birth_time)
        self.simplices = simplices
        
        logger.info(f"Built simplicial complex with {len(simplices)} simplices")
        return simplices
    
    def _build_triangles(self, points: np.ndarray, max_distance: float) -> List[Simplex]:
        """Build 2-simplices (triangles) from point cloud."""
        triangles = []
        n_points = len(points)
        
        for i in range(n_points):
            for j in range(i + 1, n_points):
                for k in range(j + 1, n_points):
                    # Check if all edges exist
                    d_ij = np.linalg.norm(points[i] - points[j])
                    d_ik = np.linalg.norm(points[i] - points[k])
                    d_jk = np.linalg.norm(points[j] - points[k])
                    
                    if d_ij <= max_distance and d_ik <= max_distance and d_jk <= max_distance:
                        # Birth time is the maximum of the three edge distances
                        birth_time = unified_math.max(d_ij, d_ik, d_jk)
                        triangles.append(Simplex(vertices=[i, j, k], dimension=2, birth_time=birth_time))
        
        return triangles
    
    def _build_tetrahedra(self, points: np.ndarray, max_distance: float) -> List[Simplex]:
        """Build 3-simplices (tetrahedra) from point cloud."""
        tetrahedra = []
        n_points = len(points)
        
        for i in range(n_points):
            for j in range(i + 1, n_points):
                for k in range(j + 1, n_points):
                    for l in range(k + 1, n_points):
                        # Check if all edges exist
                        edges = [
                            np.linalg.norm(points[i] - points[j]),
                            np.linalg.norm(points[i] - points[k]),
                            np.linalg.norm(points[i] - points[l]),
                            np.linalg.norm(points[j] - points[k]),
                            np.linalg.norm(points[j] - points[l]),
                            np.linalg.norm(points[k] - points[l])
                        ]
                        
                        if all(d <= max_distance for d in edges):
                            birth_time = unified_math.max(edges)
                            tetrahedra.append(Simplex(vertices=[i, j, k, l], dimension=3, birth_time=birth_time))
        
        return tetrahedra
    
    def compute_persistence(self) -> List[PersistentFeature]:
        """Compute persistent homology of the simplicial complex."""
        if not self.simplices:
            logger.warning("No simplices available for persistence computation")
            return []
        
        # Sort simplices by birth time
        sorted_simplices = sorted(self.simplices, key=lambda s: s.birth_time)
        
        # Initialize boundary matrix
        max_dim = unified_math.max(s.dimension for s in sorted_simplices)
        boundary_matrices = self._build_boundary_matrices(sorted_simplices, max_dim)
        
        # Compute persistence pairs
        persistence_pairs = self._compute_persistence_pairs(boundary_matrices, sorted_simplices)
        
        # Convert to persistent features
        persistent_features = []
        for birth_idx, death_idx in persistence_pairs:
            if death_idx is not None:
                birth_simplex = sorted_simplices[birth_idx]
                death_simplex = sorted_simplices[death_idx]
                
                feature = PersistentFeature(
                    feature_id=f"feature_{len(persistent_features)}",
                    dimension=birth_simplex.dimension,
                    birth_time=birth_simplex.birth_time,
                    death_time=death_simplex.birth_time,
                    persistence=death_simplex.birth_time - birth_simplex.birth_time,
                    vertices=birth_simplex.vertices.copy()
                )
                
                # Compute confidence based on persistence
                feature.confidence = unified_math.min(1.0, feature.persistence / self.persistence_threshold)
                
                if feature.persistence >= self.persistence_threshold:
                    persistent_features.append(feature)
        
        self.persistent_features = persistent_features
        logger.info(f"Computed {len(persistent_features)} persistent features")
        return persistent_features
    
    def _build_boundary_matrices(self, simplices: List[Simplex], max_dim: int) -> List[np.ndarray]:
        """Build boundary matrices for each dimension."""
        boundary_matrices = []
        
        for dim in range(max_dim + 1):
            dim_simplices = [s for s in simplices if s.dimension == dim]
            if not dim_simplices:
                boundary_matrices.append(np.array([]))
                continue
            
            # Build boundary matrix for this dimension
            matrix = np.zeros((len(dim_simplices), len(simplices)))
            
            for i, simplex in enumerate(dim_simplices):
                # Compute boundary of this simplex
                boundary = self._compute_boundary(simplex, simplices)
                for j, coeff in boundary:
                    matrix[i, j] = coeff
            
            boundary_matrices.append(matrix)
        
        return boundary_matrices
    
    def _compute_boundary(self, simplex: Simplex, all_simplices: List[Simplex]) -> List[Tuple[int, int]]:
        """Compute boundary of a simplex."""
        boundary = []
        vertices = simplex.vertices
        
        for i in range(len(vertices)):
            # Remove vertex i to get boundary face
            face_vertices = vertices[:i] + vertices[i+1:]
            face_vertices.sort()
            
            # Find this face in all_simplices
            for j, other_simplex in enumerate(all_simplices):
                if other_simplex.vertices == face_vertices:
                    # Sign depends on position of removed vertex
                    sign = (-1) ** i
                    boundary.append((j, sign))
                    break
        
        return boundary
    
    def _compute_persistence_pairs(self, boundary_matrices: List[np.ndarray], simplices: List[Simplex]) -> List[Tuple[int, Optional[int]]]:
        """Compute persistence pairs using matrix reduction."""
        # Simplified implementation - in practice, use more sophisticated algorithms
        persistence_pairs = []
        
        for dim in range(len(boundary_matrices)):
            matrix = boundary_matrices[dim]
            if matrix.size == 0:
                continue
            
            # Find pairs by looking for non-zero entries
            for i in range(matrix.shape[0]):
                for j in range(matrix.shape[1]):
                    if matrix[i, j] != 0:
                        # This is a simplified pairing - real implementation would be more complex
                        persistence_pairs.append((j, i))
                        break
        
        return persistence_pairs
    
    def analyze_market_patterns(self, price_data: np.ndarray, window_size: int = 100) -> Dict[str, Any]:
        """Analyze market patterns using persistent homology."""
        if len(price_data) < window_size:
            logger.warning("Insufficient data for pattern analysis")
            return {}
        
        # Extract features from price data
        features = self._extract_price_features(price_data, window_size)
        
        # Build simplicial complex
        max_distance = unified_math.unified_math.std(features) * 2.0  # Adaptive distance threshold
        self.build_simplicial_complex(features, max_distance)
        
        # Compute persistence
        persistent_features = self.compute_persistence()
        
        # Analyze patterns
        pattern_analysis = {
            "total_features": len(persistent_features),
            "feature_dimensions": {},
            "persistence_distribution": [],
            "confidence_scores": [],
            "significant_features": []
        }
        
        for feature in persistent_features:
            # Count by dimension
            dim = feature.dimension
            pattern_analysis["feature_dimensions"][dim] = pattern_analysis["feature_dimensions"].get(dim, 0) + 1
            
            # Collect persistence values
            pattern_analysis["persistence_distribution"].append(feature.persistence)
            pattern_analysis["confidence_scores"].append(feature.confidence)
            
            # Identify significant features
            if feature.confidence >= self.confidence_threshold:
                pattern_analysis["significant_features"].append({
                    "id": feature.feature_id,
                    "dimension": feature.dimension,
                    "persistence": feature.persistence,
                    "confidence": feature.confidence,
                    "vertices": feature.vertices
                })
        
        return pattern_analysis
    
    def _extract_price_features(self, price_data: np.ndarray, window_size: int) -> np.ndarray:
        """Extract features from price data for topological analysis."""
        features = []
        
        for i in range(len(price_data) - window_size + 1):
            window = price_data[i:i + window_size]
            
            # Compute various features
            returns = np.diff(window) / window[:-1]
            volatility = unified_math.unified_math.std(returns)
            trend = np.polyfit(range(len(window)), window, 1)[0]
            
            # Normalize features
            features.append([volatility, trend, unified_math.unified_math.mean(window)])
        
        return np.array(features)
    
    def get_topological_signals(self) -> List[Dict[str, Any]]:
        """Get topological signals for trading decisions."""
        signals = []
        
        for feature in self.persistent_features:
            if feature.confidence >= self.confidence_threshold:
                signal = {
                    "type": "topological_feature",
                    "dimension": feature.dimension,
                    "persistence": feature.persistence,
                    "confidence": feature.confidence,
                    "strength": unified_math.min(1.0, feature.persistence / self.persistence_threshold),
                    "timestamp": datetime.now(),
                    "metadata": feature.metadata
                }
                signals.append(signal)
        
        return signals


def main() -> None:
    """Main function for testing persistent homology."""
    # Initialize analyzer
    analyzer = PersistentHomology()
    
    # Generate sample price data
    np.random.seed(42)
    price_data = np.cumsum(np.random.randn(1000) * 0.01) + 100
    
    # Analyze patterns
    pattern_analysis = analyzer.analyze_market_patterns(price_data)
    safe_print(f"Pattern analysis: {pattern_analysis}")
    
    # Get topological signals
    signals = analyzer.get_topological_signals()
    safe_print(f"Topological signals: {len(signals)}")


if __name__ == "__main__":
    main() 